{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6ce9a-e975-44a1-8675-e4ec03c97175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import requests\n",
    "from os import path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from rectangle import Rectangle\n",
    "import helpers\n",
    "from helpers import *\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "kindle_ar = (1430,1080)\n",
    "\n",
    "if not path.exists(f'dump'):\n",
    "    os.mkdir('dump')\n",
    "\n",
    "manga_name = 'Onepunch-Man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6e681-12d9-4305-920d-7617c219d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += \":\"+os.getcwd()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.get(\"https://mangasee123.com/manga/\"+manga_name)\n",
    "# with open('mangasee.html', 'w', encoding='utf-8') as f:\n",
    "#     f.write(driver.page_source)\n",
    "selector = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'div.ShowAllChapters')))\n",
    "selector.click()\n",
    "\n",
    "chapter_links = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, 'a[href*=\"read-online\"]')]\n",
    "chapter_links = reversed(chapter_links)\n",
    "pages = {}\n",
    "for chapter in chapter_links:\n",
    "    driver.get(chapter)\n",
    "\n",
    "    selector = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'i.fa-arrows-alt-v')))\n",
    "    selector.click()\n",
    "\n",
    "    img_links = [img.get_attribute('src') for img in driver.find_elements(By.CSS_SELECTOR, 'img.img-fluid')]\n",
    "    pages[chapter.split('/')[-1]] = img_links\n",
    "with open(manga_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(pages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cef4a2-5c1c-4513-9105-32ea5537093d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_page(url, chapter_counter, page_counter):\n",
    "    # print(url)\n",
    "    try:\n",
    "        raw_img = requests.get(url, stream=True).raw\n",
    "        img = np.array(Image.open(raw_img))\n",
    "        if img.ndim==2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    # if not path.exists(f'dump/{manga_name}/{chapter_counter:04d}'):\n",
    "    #     os.mkdir(f'dump/{manga_name}/{chapter_counter:04d}')\n",
    "    # img = cv2.imread('0012-002.png')\n",
    "    # plot_crops(img, [])\n",
    "    contours = get_contours(img)\n",
    "    contours = remove_specks_and_lines(img, contours)\n",
    "    crops = get_crops(img, contours)\n",
    "    crops = merge_overlapping_crops(crops)\n",
    "    crops = remove_small_crops(img, crops)\n",
    "    helpers.debug = False\n",
    "\n",
    "    text_crops = get_text_crops(img)\n",
    "    text_crops = remove_small_crops(img, text_crops, factor=0.5)\n",
    "\n",
    "    crops.extend(text_crops)\n",
    "    crops = merge_overlapping_crops(crops)\n",
    "\n",
    "    # debug = True\n",
    "    # plot_frames(img, crops, True)\n",
    "    edge_graph = build_crops_edge_graph(crops, img.shape)\n",
    "    # print(*[(i,j) for i,j in enumerate(edge_graph)], sep='\\n')\n",
    "    sorted_crops = sort_edge_graph(crops, edge_graph)\n",
    "    idx = 0\n",
    "    if len(sorted_crops)==1:\n",
    "        sorted_crops = [Rectangle(0,0,img.shape[1],img.shape[0])]\n",
    "\n",
    "#         crop_area = sum([c.area for c in sorted_crops])\n",
    "#         total_area = img.shape[0]*img.shape[1]\n",
    "\n",
    "#         if crop_area/total_area < 0.80:\n",
    "#             sorted_crops = [Rectangle(0,0,img.shape[1],img.shape[0])]\n",
    "\n",
    "    image = plot_frames(img, sorted_crops, True, show=helpers.debug)\n",
    "    for c in sorted_crops:\n",
    "        gray_crop = cv2.cvtColor(img[c.y:c.z, c.x:c.w], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if gray_crop.shape[1]/gray_crop.shape[0]>0.80 or c.area < img.shape[0]*img.shape[1]*0.5:\n",
    "            gray_crop = [np.rot90(gray_crop)]\n",
    "        else:\n",
    "            text_crops = merge_vertical_overlapping_crops(text_crops)\n",
    "            if len(text_crops)==0:\n",
    "                middleh = c.height//2+c.y\n",
    "            elif len(text_crops)==1:\n",
    "                middleh = c.height//2+c.y\n",
    "                if text_crops[0].y<=middleh and middleh<=text_crops[0].z:\n",
    "                    middleh = text_crops[0].y if text_crops[0].y-middleh < middleh-text_crops[0].z else text_crops[0].z\n",
    "            else: # find the widest gat\n",
    "                def pairwise(iterable):\n",
    "                    a = iter(iterable)\n",
    "                    return zip(a, a)\n",
    "                widest_gap = max([(idx,j.y-i.z) for idx,(i,j) in enumerate(list(pairwise(text_crops)))], key=lambda t: t[1])\n",
    "                middleh = text_crops[widest_gap[0]].z+widest_gap[1]//2\n",
    "            # cv2.line(image, (c.x, middleh), (c.w, middleh), (0, 255, 0), thickness=3)\n",
    "            gray_crop = [np.rot90(h) for h in np.split(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), [middleh])]\n",
    "\n",
    "        if helpers.debug:\n",
    "            plot_crops(image,[])\n",
    "        # cv2.imwrite(f\"dump/{manga_name}/{chapter_counter:04d}/{page_counter:03d}.jpg\", image, [int(cv2.IMWRITE_JPEG_QUALITY), 20])\n",
    "        for gc in gray_crop:\n",
    "            gc = resizeAndPad(gc, kindle_ar, 255)\n",
    "            cv2.imwrite(f\"dump/{manga_name}/{chapter_counter:04d}-{page_counter:03d}-{idx:03d}.jpg\", gc, [int(cv2.IMWRITE_JPEG_QUALITY), 20])\n",
    "            idx+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3af6b-d123-4792-a99f-065fa9542955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists(f'dump/{manga_name}'):\n",
    "    os.mkdir(f'dump/{manga_name}')\n",
    "\n",
    "with open(manga_name+'.pkl', 'rb') as f:\n",
    "    pages = pickle.load(f)\n",
    "\n",
    "chapter_counter = 0\n",
    "page_counter = 5\n",
    "chap = [*pages.keys()][chapter_counter]\n",
    "url = pages[chap][page_counter]\n",
    "helpers.debug = False\n",
    "process_page(url, chapter_counter, page_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77314c03-5b05-49cf-afed-198ad8775019",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "pool = Pool(processes=(cpu_count() - 1))\n",
    "\n",
    "if not path.exists(f'dump/{manga_name}'):\n",
    "    os.mkdir(f'dump/{manga_name}')\n",
    "\n",
    "with open(manga_name+'.pkl', 'rb') as f:\n",
    "    pages = pickle.load(f)\n",
    "\n",
    "for chapter_counter,chap in enumerate(pages.keys()):\n",
    "    # if chapter_counter!=3: continue\n",
    "    for page_counter, url in enumerate(tqdm(pages[chap], desc=f'Chapter {chapter_counter}: {chap}')):\n",
    "        # if 'Onepunch-Man-chapter-63-page-1.html' not in chap: continue\n",
    "        # if page_counter!=23: continue\n",
    "        # print(i)\n",
    "        pool.apply_async(process_page, args=(url, chapter_counter, page_counter))\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65054d1-26a6-454b-8c4f-099c4c167a32",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(f\"cd dump; zip -FSr {manga_name} {manga_name} -x '*/\\.*'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kumiko",
   "language": "python",
   "name": "kumiko"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "68a41b7eb7f97a56dfe91caaf3fc1bc75b1839613c13e501145be387320902b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
